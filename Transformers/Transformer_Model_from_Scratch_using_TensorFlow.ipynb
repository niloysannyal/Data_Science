{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Embedding, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Positional Encoding\n",
    "# ----------------------------\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = np.arange(position)[:, np.newaxis] / np.power(\n",
    "        10000, (2 * (np.arange(d_model) // 2)) / np.float32(d_model)\n",
    "    )\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "# ----------------------------\n",
    "# Multi-head Attention\n",
    "# ----------------------------\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % num_heads == 0\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        self.wq = Dense(d_model)\n",
    "        self.wk = Dense(d_model)\n",
    "        self.wv = Dense(d_model)\n",
    "        self.dense = Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        if mask is not None:\n",
    "            scaled_logits += (mask * -1e9)\n",
    "        attention_weights = tf.nn.softmax(scaled_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def call(self, v, k, q, mask=None):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        scaled_attention, _ = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        return self.dense(concat_attention)\n",
    "\n",
    "# ----------------------------\n",
    "# Feed Forward\n",
    "# ----------------------------\n",
    "class PositionwiseFeedforward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff):\n",
    "        super().__init__()\n",
    "        self.dense1 = Dense(dff, activation='relu')\n",
    "        self.dense2 = Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.dense2(self.dense1(x))\n",
    "\n",
    "# ----------------------------\n",
    "# Transformer Block\n",
    "# ----------------------------\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionwiseFeedforward(d_model, dff)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        attn_output = self.att(x, x, x, mask=mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "# ----------------------------\n",
    "# Encoder\n",
    "# ----------------------------\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "                 maximum_position_encoding, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.enc_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate)\n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x) * tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, training=training, mask=mask)\n",
    "        return x\n",
    "\n",
    "# ----------------------------\n",
    "# Decoder\n",
    "# ----------------------------\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "                 maximum_position_encoding, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.dec_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate)\n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, enc_output, training=False, look_ahead_mask=None):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x) * tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, training=training, mask=look_ahead_mask)\n",
    "        return x\n",
    "\n",
    "# ----------------------------\n",
    "# Transformer Model\n",
    "# ----------------------------\n",
    "class Transformer(Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff,\n",
    "                 input_vocab_size, target_vocab_size, maximum_position_encoding,\n",
    "                 dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                               input_vocab_size, maximum_position_encoding, dropout_rate)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, maximum_position_encoding, dropout_rate)\n",
    "        self.final_layer = Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inputs, training=False, look_ahead_mask=None, padding_mask=None):\n",
    "        inp, tar = inputs\n",
    "        enc_output = self.encoder(inp, training=training, mask=padding_mask)\n",
    "        dec_output = self.decoder(tar, enc_output, training=training,\n",
    "                                  look_ahead_mask=look_ahead_mask)\n",
    "        return self.final_layer(dec_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Data Preparation\n",
    "# ----------------------------\n",
    "with open('./data/shakespere_dataset.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "char2idx = {u:i for i,u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "seq_length = 50  # shorter sequence for testing\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    return chunk[:-1], chunk[1:]\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = dataset.map(lambda x, y: (tf.cast(x, tf.int32), tf.cast(y, tf.int32)))\n",
    "\n",
    "# ----------------------------\n",
    "# Mask\n",
    "# ----------------------------\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer_10/encoder_10/embedding_18/embeddings:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_416/kernel:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_416/bias:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_417/kernel:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_417/bias:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_418/kernel:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_418/bias:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_419/kernel:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_419/bias:0', 'transformer_10/encoder_10/transformer_block_70/positionwise_feedforward_68/dense_420/kernel:0', 'transformer_10/encoder_10/transformer_block_70/positionwise_feedforward_68/dense_420/bias:0', 'transformer_10/encoder_10/transformer_block_70/positionwise_feedforward_68/dense_421/kernel:0', 'transformer_10/encoder_10/transformer_block_70/positionwise_feedforward_68/dense_421/bias:0', 'transformer_10/encoder_10/transformer_block_70/layer_normalization_136/gamma:0', 'transformer_10/encoder_10/transformer_block_70/layer_normalization_136/beta:0', 'transformer_10/encoder_10/transformer_block_70/layer_normalization_137/gamma:0', 'transformer_10/encoder_10/transformer_block_70/layer_normalization_137/beta:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_422/kernel:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_422/bias:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_423/kernel:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_423/bias:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_424/kernel:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_424/bias:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_425/kernel:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_425/bias:0', 'transformer_10/encoder_10/transformer_block_71/positionwise_feedforward_69/dense_426/kernel:0', 'transformer_10/encoder_10/transformer_block_71/positionwise_feedforward_69/dense_426/bias:0', 'transformer_10/encoder_10/transformer_block_71/positionwise_feedforward_69/dense_427/kernel:0', 'transformer_10/encoder_10/transformer_block_71/positionwise_feedforward_69/dense_427/bias:0', 'transformer_10/encoder_10/transformer_block_71/layer_normalization_138/gamma:0', 'transformer_10/encoder_10/transformer_block_71/layer_normalization_138/beta:0', 'transformer_10/encoder_10/transformer_block_71/layer_normalization_139/gamma:0', 'transformer_10/encoder_10/transformer_block_71/layer_normalization_139/beta:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_428/kernel:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_428/bias:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_429/kernel:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_429/bias:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_430/kernel:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_430/bias:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_431/kernel:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_431/bias:0', 'transformer_10/encoder_10/transformer_block_72/positionwise_feedforward_70/dense_432/kernel:0', 'transformer_10/encoder_10/transformer_block_72/positionwise_feedforward_70/dense_432/bias:0', 'transformer_10/encoder_10/transformer_block_72/positionwise_feedforward_70/dense_433/kernel:0', 'transformer_10/encoder_10/transformer_block_72/positionwise_feedforward_70/dense_433/bias:0', 'transformer_10/encoder_10/transformer_block_72/layer_normalization_140/gamma:0', 'transformer_10/encoder_10/transformer_block_72/layer_normalization_140/beta:0', 'transformer_10/encoder_10/transformer_block_72/layer_normalization_141/gamma:0', 'transformer_10/encoder_10/transformer_block_72/layer_normalization_141/beta:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_434/kernel:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_434/bias:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_435/kernel:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_435/bias:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_436/kernel:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_436/bias:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_437/kernel:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_437/bias:0', 'transformer_10/encoder_10/transformer_block_73/positionwise_feedforward_71/dense_438/kernel:0', 'transformer_10/encoder_10/transformer_block_73/positionwise_feedforward_71/dense_438/bias:0', 'transformer_10/encoder_10/transformer_block_73/positionwise_feedforward_71/dense_439/kernel:0', 'transformer_10/encoder_10/transformer_block_73/positionwise_feedforward_71/dense_439/bias:0', 'transformer_10/encoder_10/transformer_block_73/layer_normalization_142/gamma:0', 'transformer_10/encoder_10/transformer_block_73/layer_normalization_142/beta:0', 'transformer_10/encoder_10/transformer_block_73/layer_normalization_143/gamma:0', 'transformer_10/encoder_10/transformer_block_73/layer_normalization_143/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer_10/encoder_10/embedding_18/embeddings:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_416/kernel:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_416/bias:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_417/kernel:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_417/bias:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_418/kernel:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_418/bias:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_419/kernel:0', 'transformer_10/encoder_10/transformer_block_70/multi_head_attention_70/dense_419/bias:0', 'transformer_10/encoder_10/transformer_block_70/positionwise_feedforward_68/dense_420/kernel:0', 'transformer_10/encoder_10/transformer_block_70/positionwise_feedforward_68/dense_420/bias:0', 'transformer_10/encoder_10/transformer_block_70/positionwise_feedforward_68/dense_421/kernel:0', 'transformer_10/encoder_10/transformer_block_70/positionwise_feedforward_68/dense_421/bias:0', 'transformer_10/encoder_10/transformer_block_70/layer_normalization_136/gamma:0', 'transformer_10/encoder_10/transformer_block_70/layer_normalization_136/beta:0', 'transformer_10/encoder_10/transformer_block_70/layer_normalization_137/gamma:0', 'transformer_10/encoder_10/transformer_block_70/layer_normalization_137/beta:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_422/kernel:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_422/bias:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_423/kernel:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_423/bias:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_424/kernel:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_424/bias:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_425/kernel:0', 'transformer_10/encoder_10/transformer_block_71/multi_head_attention_71/dense_425/bias:0', 'transformer_10/encoder_10/transformer_block_71/positionwise_feedforward_69/dense_426/kernel:0', 'transformer_10/encoder_10/transformer_block_71/positionwise_feedforward_69/dense_426/bias:0', 'transformer_10/encoder_10/transformer_block_71/positionwise_feedforward_69/dense_427/kernel:0', 'transformer_10/encoder_10/transformer_block_71/positionwise_feedforward_69/dense_427/bias:0', 'transformer_10/encoder_10/transformer_block_71/layer_normalization_138/gamma:0', 'transformer_10/encoder_10/transformer_block_71/layer_normalization_138/beta:0', 'transformer_10/encoder_10/transformer_block_71/layer_normalization_139/gamma:0', 'transformer_10/encoder_10/transformer_block_71/layer_normalization_139/beta:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_428/kernel:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_428/bias:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_429/kernel:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_429/bias:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_430/kernel:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_430/bias:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_431/kernel:0', 'transformer_10/encoder_10/transformer_block_72/multi_head_attention_72/dense_431/bias:0', 'transformer_10/encoder_10/transformer_block_72/positionwise_feedforward_70/dense_432/kernel:0', 'transformer_10/encoder_10/transformer_block_72/positionwise_feedforward_70/dense_432/bias:0', 'transformer_10/encoder_10/transformer_block_72/positionwise_feedforward_70/dense_433/kernel:0', 'transformer_10/encoder_10/transformer_block_72/positionwise_feedforward_70/dense_433/bias:0', 'transformer_10/encoder_10/transformer_block_72/layer_normalization_140/gamma:0', 'transformer_10/encoder_10/transformer_block_72/layer_normalization_140/beta:0', 'transformer_10/encoder_10/transformer_block_72/layer_normalization_141/gamma:0', 'transformer_10/encoder_10/transformer_block_72/layer_normalization_141/beta:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_434/kernel:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_434/bias:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_435/kernel:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_435/bias:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_436/kernel:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_436/bias:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_437/kernel:0', 'transformer_10/encoder_10/transformer_block_73/multi_head_attention_73/dense_437/bias:0', 'transformer_10/encoder_10/transformer_block_73/positionwise_feedforward_71/dense_438/kernel:0', 'transformer_10/encoder_10/transformer_block_73/positionwise_feedforward_71/dense_438/bias:0', 'transformer_10/encoder_10/transformer_block_73/positionwise_feedforward_71/dense_439/kernel:0', 'transformer_10/encoder_10/transformer_block_73/positionwise_feedforward_71/dense_439/bias:0', 'transformer_10/encoder_10/transformer_block_73/layer_normalization_142/gamma:0', 'transformer_10/encoder_10/transformer_block_73/layer_normalization_142/beta:0', 'transformer_10/encoder_10/transformer_block_73/layer_normalization_143/gamma:0', 'transformer_10/encoder_10/transformer_block_73/layer_normalization_143/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Epoch 1, Loss: 2.6636\n",
      "Epoch 2, Loss: 1.9895\n",
      "Epoch 3, Loss: 1.8139\n",
      "Epoch 4, Loss: 1.7217\n",
      "Epoch 5, Loss: 1.6621\n",
      "Epoch 6, Loss: 1.6200\n",
      "Epoch 7, Loss: 1.5871\n",
      "Epoch 8, Loss: 1.5611\n",
      "Epoch 9, Loss: 1.5413\n",
      "Epoch 10, Loss: 1.5234\n",
      "Epoch 11, Loss: 1.5089\n",
      "Epoch 12, Loss: 1.4952\n",
      "Epoch 13, Loss: 1.4834\n",
      "Epoch 14, Loss: 1.4740\n",
      "Epoch 15, Loss: 1.4651\n",
      "Epoch 16, Loss: 1.4574\n",
      "Epoch 17, Loss: 1.4502\n",
      "Epoch 18, Loss: 1.4425\n",
      "Epoch 19, Loss: 1.4371\n",
      "Epoch 20, Loss: 1.4319\n",
      "Epoch 21, Loss: 1.4260\n",
      "Epoch 22, Loss: 1.4203\n",
      "Epoch 23, Loss: 1.4161\n",
      "Epoch 24, Loss: 1.4120\n",
      "Epoch 25, Loss: 1.4083\n",
      "Epoch 26, Loss: 1.4042\n",
      "Epoch 27, Loss: 1.4010\n",
      "Epoch 28, Loss: 1.3967\n",
      "Epoch 29, Loss: 1.3944\n",
      "Epoch 30, Loss: 1.3910\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Training\n",
    "# ----------------------------\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 4\n",
    "dropout_rate = 0.1\n",
    "input_vocab_size = vocab_size\n",
    "target_vocab_size = vocab_size\n",
    "maximum_position_encoding = 1000\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, maximum_position_encoding,\n",
    "                          dropout_rate)\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1])\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = transformer((inp, tar_inp), training=True,\n",
    "                                  look_ahead_mask=look_ahead_mask)\n",
    "        loss = loss_object(tar_real, predictions)\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "EPOCHS = 30\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        batch_loss = train_step(inp, tar)\n",
    "        total_loss += batch_loss\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/(batch+1):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Generate Text (Chatbot Response)\n",
    "# ----------------------------\n",
    "def generate_response(model, start_string, num_generate=200):\n",
    "    # Convert input string to int tokens\n",
    "    input_eval = [char2idx[s] for s in start_string if s in char2idx]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Decoder input starts with the same\n",
    "    text_generated = []\n",
    "\n",
    "    # Reset model states\n",
    "    for i in range(num_generate):\n",
    "        # Pass input and current decoder sequence\n",
    "        predictions = model((input_eval, input_eval), training=False)\n",
    "\n",
    "        # Get predictions for the last time step\n",
    "        predictions = predictions[:, -1:, :]  # (batch, 1, vocab_size)\n",
    "        predicted_id = tf.random.categorical(predictions[0], num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # Append prediction\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "        # Update decoder input\n",
    "        input_eval = tf.concat([input_eval, [[predicted_id]]], axis=-1)\n",
    "\n",
    "    return start_string + ''.join(text_generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Shakespeare Chatbot ===\n",
      "Type 'quit' to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi baby\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: , why staide, but fine:\n",
      "At wo when I afteringes, ly, me.\n",
      "A jat y the med tith thernormeth, t ash, on\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  down angliants should none,\n",
      "Thuncy bagot, lark h ast yede itashone ionck, aths tonde th me: at whin\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Interactive Chat\n",
    "# ----------------------------\n",
    "def chat():\n",
    "    print(\"=== Shakespeare Chatbot ===\")\n",
    "    print(\"Type 'quit' to exit.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"quit\":\n",
    "            break\n",
    "        response = generate_response(transformer, user_input, num_generate=100)\n",
    "        print(\"Bot:\", response[len(user_input):])  # show only continuation\n",
    "\n",
    "# ----------------------------\n",
    "# Example Usage after Training\n",
    "# ----------------------------\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
