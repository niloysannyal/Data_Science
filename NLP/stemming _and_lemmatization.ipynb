{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9088b6c0-e1fd-4a9e-b8fc-1ab590d5a20d",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;color:mediumvioletred\">Stemming & Lemmatization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0777faeb-5543-45ec-a214-471093350d06",
   "metadata": {},
   "source": [
    "### 1. Stemming\n",
    "    Use fixed rules such as remove able, ing, ly etc. to derive a base word\n",
    "\n",
    "    talking    --> talk\n",
    "    eating     --> eat\n",
    "    adjustable --> adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4aa1c1-35e3-4c74-a706-a4248162844d",
   "metadata": {},
   "source": [
    "### 2. Lemmatization\n",
    "    Here we need knowledge of a language(a.k.a. linguistic knowledge) to derive a base word\n",
    "    \n",
    "    ate     --> eat\n",
    "    better  --> good\n",
    "    wrote   --> write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6cd909-faf5-4f58-b9a4-768246e34dbb",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf7fcf23-a22f-4223-85be-6ed85a15b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07e7de5-0d65-4335-9fc2-81bd98cbd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer =  PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086c385a-2409-44fa-84f7-2f8d7e5fc13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The | the\n",
      "cats | cat\n",
      "are | are\n",
      "running | run\n",
      "faster | faster\n",
      "than | than\n",
      "the | the\n",
      "dogs | dog\n"
     ]
    }
   ],
   "source": [
    "text = (\"The cats are running faster than the dogs\")\n",
    "words = text.split(\" \")\n",
    "\n",
    "for word in words:\n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0a4359a-5468-4af5-b3f9-1a542f9ea4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The | the\n",
      "mice | mice\n",
      "were | were\n",
      "eating | eat\n",
      "the | the\n",
      "cheeses | chees\n",
      "while | while\n",
      "the | the\n",
      "men | men\n",
      "sang | sang\n",
      "happily | happili\n",
      "and | and\n",
      "became | becam\n",
      "tired | tire\n"
     ]
    }
   ],
   "source": [
    "text = (\"The mice were eating the cheeses while the men sang happily and became tired\")\n",
    "words = text.split(\" \")\n",
    "\n",
    "for word in words:\n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8975f66-20da-4b74-918a-6f5dcdc5717a",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "616d7b8f-3b76-4dda-b354-58aaa59f2224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The | the | 7425985699627899538\n",
      "children | child | 737253710922290542\n",
      "were | be | 10382539506755952630\n",
      "running | run | 12767647472892411841\n",
      "quickly | quickly | 7007696535375059571\n",
      "towards | towards | 9315050841437086371\n",
      "the | the | 7425985699627899538\n",
      "better | well | 4525988469032889948\n",
      "houses | house | 9471806766518506264\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"The children were running quickly towards the better houses\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"|\", word.lemma_, \"|\", word.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3b1c56b-d564-4721-b9b1-61f7a17c9dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The | the\n",
      "mice | mouse\n",
      "were | be\n",
      "eating | eat\n",
      "the | the\n",
      "cheeses | cheese\n",
      "while | while\n",
      "the | the\n",
      "men | man\n",
      "sang | sing\n",
      "happily | happily\n",
      "and | and\n",
      "became | become\n",
      "tired | tired\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The mice were eating the cheeses while the men sang happily and became tired\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"|\", word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fbed6e1-ff26-474f-804d-b14c8aae5f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f29437-8320-44c0-bf22-b03dd693b337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | Bro\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Brah | Brah\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word.text, \"|\", word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6efecd82-67c3-4fd5-9554-51c487ac0fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bro"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "755135a5-4440-4e4c-8683-54b2620e02b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bro'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41a70499-f3a0-4bef-be79-112e25a97319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | Brother\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Brah | Brother\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "\n",
    "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Brah\"}]], {\"LEMMA\": \"Brother\"})\n",
    "\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word.text, \"|\", word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "275796b8-7ee8-4016-8e46-9e4ce8f74ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bro"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f614a293-ed8f-4a2c-92c9-cf724523258f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brother'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "729add51-e611-4155-b3ea-8c72a17e62d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brah"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75899888-9e28-41cc-b689-a34705e13737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brother'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[6].lemma_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e907bf3-281e-4821-b90b-a38c18d8fd91",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da91f8-6f07-4c8e-8591-e5c5d0ec2c58",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "- Convert these list of words into base form using Stemming and Lemmatization and observe the transformations\n",
    "- Write a short note on the words that have different base words using stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b3420f4-8bdf-49a7-9b60-5a867be6273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n",
    "\n",
    "text2 = \"running painting walking dressing likely children who good ate fishing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281d0ae3-8d87-48aa-b379-1c964c512408",
   "metadata": {},
   "source": [
    "#### Stemming using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9d91853-5330-4551-a6ad-f9c0ae56e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a8a2a46e-25d0-4bc1-b9ce-a8712bb0e5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw word   -->   Stem\n",
      "------------------------------\n",
      "running    -->    run\n",
      "painting    -->    paint\n",
      "walking    -->    walk\n",
      "dressing    -->    dress\n",
      "likely    -->    like\n",
      "children    -->    children\n",
      "whom    -->    whom\n",
      "good    -->    good\n",
      "ate    -->    ate\n",
      "fishing    -->    fish\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw word   -->   Stem\")\n",
    "print(\"-\"*30)\n",
    "given_words = []\n",
    "stems = []\n",
    "for word in text1:\n",
    "    stem = stemmer.stem(word)\n",
    "    given_words.append(word)\n",
    "    stems.append(stem)\n",
    "    print(word,\"   -->   \",stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf3cf4-d73b-4ac9-81b2-7f2f14587a3e",
   "metadata": {},
   "source": [
    "#### Lemmatization using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0b0a213-960a-4a36-9d30-97d10a295038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ddabdb8-202c-4f05-8a1f-49a6e42e5b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw word   -->   Lemma\n",
      "------------------------------\n",
      "running    -->    run\n",
      "painting    -->    paint\n",
      "walking    -->    walk\n",
      "dressing    -->    dress\n",
      "likely    -->    likely\n",
      "children    -->    child\n",
      "whom    -->    whom\n",
      "good    -->    good\n",
      "ate    -->    eat\n",
      "fishing    -->    fishing\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"running painting walking dressing likely children whom good ate fishing\")\n",
    "\n",
    "print(\"Raw word   -->   Lemma\")\n",
    "print(\"-\"*30)\n",
    "lemmas = []\n",
    "for word in doc:\n",
    "    lemma = word.lemma_\n",
    "    lemmas.append(lemma)\n",
    "    print(word.text, \"   -->   \",lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2eefc1-de1a-4e56-a2c7-97a235e8a75c",
   "metadata": {},
   "source": [
    "#### Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b462ba85-6db5-4f30-9c7d-27343f891620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given words   -->   Stems  -->  Lemmas\n",
      "----------------------------------------\n",
      "likely    -->    like    -->    likely\n",
      "children    -->    children    -->    child\n",
      "ate    -->    ate    -->    eat\n",
      "fishing    -->    fish    -->    fishing\n"
     ]
    }
   ],
   "source": [
    "print(\"Given words   -->   Stems  -->  Lemmas\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for i in range(len(given_words)):\n",
    "    if stems[i] != lemmas[i]:\n",
    "        print(given_words[i], \"   -->   \", stems[i], \"   -->   \", lemmas[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c4bd8f-4da8-402a-8925-66afa5c92eb6",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "- convert the given text into it's base form using both stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c96d0cdb-bad0-421b-a4ef-06d40fb5a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Latha is very multi talented girl. She is good at many skills like dancing, running, singing, playing. She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too. Besides all this, she is a wonderful at cooking too.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce72a92-4f4a-468e-9dbc-93667768eb6c",
   "metadata": {},
   "source": [
    "#### Stemming using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "883916de-4f88-4820-b887-8cdce20c9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5e83f7e-8b55-406e-8583-eea4bcd3af04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latha is veri multi talent girl . she is good at mani skill like danc , run , sing , play . she also like eat pav bhagi . she ha a habit of fish and swim too . besid all thi , she is a wonder at cook too .'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step1: Word tokenizing\n",
    "words = word_tokenize(text)\n",
    "\n",
    "#step2: Getting all base words\n",
    "base_words = []\n",
    "\n",
    "for word in words:\n",
    "    base_words.append(stemmer.stem(word))\n",
    "\n",
    "#joining all base words into a string\n",
    "joined = ' '.join(base_words)\n",
    "joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac8b1c-6e8e-4e93-8148-dada2f9f6e57",
   "metadata": {},
   "source": [
    "#### Using lemmatization in Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90363d04-f4e2-49a7-bbfb-f4b4d7866e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7d7a3743-9f4f-4865-ae21-5db9083221d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Latha be very multi talented girl . she be good at many skill like dance , running , singing , playing . she also like eat Pav Bhagi . she have a \\n habit of fishing and swimming too . besides all this , she be a wonderful at cook too .'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "base_words = []\n",
    "\n",
    "for word in doc:\n",
    "    lemma = word.lemma_\n",
    "    base_words.append(lemma)\n",
    "\n",
    "all_base_words = ' '.join(base_words)\n",
    "all_base_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
